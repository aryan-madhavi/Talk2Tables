# ============================================================
# Talk2Tables — Environment Variables
# Copy this file to .env and fill in your values.
# NEVER commit .env to Git.
# ============================================================

# ── LLM Provider ─────────────────────────────────────────────
# Priority order: openrouter > groq > gemini > ollama
# Set LLM_PROVIDER to override auto-detection:
LLM_PROVIDER=openrouter

# OpenRouter (PRIMARY — get key at https://openrouter.ai)
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_MODEL=qwen/qwen-2.5-coder-32b-instruct

# Groq (SECONDARY — get key at https://console.groq.com)
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=qwen-2.5-coder-32b

# Google Gemini (TERTIARY — get key at https://aistudio.google.com)
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-1.5-flash

# Ollama (OPTIONAL — local inference, no key needed)
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=qwen2.5-coder:7b

# ── Database ──────────────────────────────────────────────────
# System DB (users, roles, query history, schema docs)
DATABASE_URL=postgresql://talk2tables:password@localhost:5432/talk2tables_system

# Demo target DB (industrial sensor data — used in demos)
# DEMO_DB_URL=mysql+pymysql://user:password@localhost:3306/industrial_demo

# ── Auth ──────────────────────────────────────────────────────
SECRET_KEY=your-super-secret-jwt-key-change-this-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=60

# ── Agent Config ──────────────────────────────────────────────
MAX_HISTORY_TURNS=6          # How many conversation turns to include in LLM context
MAX_QUERY_ROWS=10000         # Hard cap on SELECT results

# ── Storage (Supabase or Cloudflare R2 for schema doc uploads) ─
# STORAGE_BUCKET_URL=https://your-project.supabase.co/storage/v1
# STORAGE_KEY=your_supabase_service_role_key

# ── App ───────────────────────────────────────────────────────
DEBUG=false
LOG_LEVEL=INFO
CORS_ORIGINS=http://localhost:3000,http://localhost:5173
